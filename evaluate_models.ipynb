{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2435565f",
   "metadata": {},
   "source": [
    "## 1. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97f91dd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('src')\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import json\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA device: {torch.cuda.get_device_name(0)}\")\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"\\nUsing device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32471cf3",
   "metadata": {},
   "source": [
    "## 2. 모델 경로 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc28ffee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 저장된 모델 체크포인트 확인\n",
    "checkpoint_dir = Path('checkpoints')\n",
    "\n",
    "print(\"Available checkpoints:\")\n",
    "if checkpoint_dir.exists():\n",
    "    for ckpt in sorted(checkpoint_dir.glob('*.pt')):\n",
    "        size_mb = ckpt.stat().st_size / (1024 * 1024)\n",
    "        print(f\"  - {ckpt.name:40s} ({size_mb:.1f} MB)\")\n",
    "else:\n",
    "    print(\"  No checkpoints directory found!\")\n",
    "    print(\"  Please train models first using 2_train_baseline.py and 4_train_multimodal.py\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37632161",
   "metadata": {},
   "source": [
    "## 3. 평가 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f565f91c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 평가 설정\n",
    "CONFIG = {\n",
    "    # 모델 경로 (위에서 확인한 경로로 수정하세요)\n",
    "    'baseline_model': 'checkpoints/baseline_best.pt',\n",
    "    'multimodal_model': 'checkpoints/multimodal_best.pt',\n",
    "    \n",
    "    # 평가 설정\n",
    "    'n_games': 1000,  # 시뮬레이션할 게임 수\n",
    "    'aggression_level': 0.5,  # Rule-based agent 공격성 (0-1)\n",
    "    'random_seed': 42,\n",
    "    \n",
    "    # 출력 설정\n",
    "    'output_dir': 'outputs',\n",
    "    'verbose': True,  # 상세 로그 출력\n",
    "    \n",
    "    # Multimodal 대화 생성 (실시간 LLM 사용 여부)\n",
    "    'use_llm_dialogue': False,  # True로 설정하면 실시간 LLM 대화 생성 (느림)\n",
    "}\n",
    "\n",
    "print(\"Configuration:\")\n",
    "for key, value in CONFIG.items():\n",
    "    print(f\"  {key:20s}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6628d739",
   "metadata": {},
   "source": [
    "## 4. Baseline 모델 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f89920da",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"BASELINE MODEL EVALUATION\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# 스크립트 실행\n",
    "import subprocess\n",
    "\n",
    "cmd = [\n",
    "    'python', '5_evaluate_vs_rule_based.py',\n",
    "    '--model_type', 'baseline',\n",
    "    '--model_path', CONFIG['baseline_model'],\n",
    "    '--n_games', str(CONFIG['n_games']),\n",
    "    '--output_dir', CONFIG['output_dir'],\n",
    "    '--device', str(device),\n",
    "]\n",
    "\n",
    "if CONFIG['verbose']:\n",
    "    cmd.append('--verbose')\n",
    "\n",
    "result = subprocess.run(cmd, capture_output=False, text=True)\n",
    "\n",
    "if result.returncode == 0:\n",
    "    print(\"\\n✓ Baseline evaluation completed successfully\")\n",
    "else:\n",
    "    print(\"\\n✗ Baseline evaluation failed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9ec6e51",
   "metadata": {},
   "source": [
    "## 5. Multimodal 모델 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6986b6d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"MULTIMODAL MODEL EVALUATION\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "cmd = [\n",
    "    'python', '5_evaluate_vs_rule_based.py',\n",
    "    '--model_type', 'multimodal',\n",
    "    '--model_path', CONFIG['multimodal_model'],\n",
    "    '--n_games', str(CONFIG['n_games']),\n",
    "    '--output_dir', CONFIG['output_dir'],\n",
    "    '--device', str(device),\n",
    "]\n",
    "\n",
    "if CONFIG['verbose']:\n",
    "    cmd.append('--verbose')\n",
    "\n",
    "result = subprocess.run(cmd, capture_output=False, text=True)\n",
    "\n",
    "if result.returncode == 0:\n",
    "    print(\"\\n✓ Multimodal evaluation completed successfully\")\n",
    "else:\n",
    "    print(\"\\n✗ Multimodal evaluation failed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63825be3",
   "metadata": {},
   "source": [
    "## 6. 결과 비교 및 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98e31b98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 결과 로드\n",
    "output_dir = Path(CONFIG['output_dir'])\n",
    "\n",
    "baseline_results = None\n",
    "multimodal_results = None\n",
    "\n",
    "baseline_file = output_dir / 'baseline_vs_rule_based.json'\n",
    "multimodal_file = output_dir / 'multimodal_vs_rule_based.json'\n",
    "\n",
    "if baseline_file.exists():\n",
    "    with open(baseline_file, 'r') as f:\n",
    "        baseline_results = json.load(f)\n",
    "    print(f\"✓ Loaded baseline results from {baseline_file}\")\n",
    "else:\n",
    "    print(f\"✗ Baseline results not found: {baseline_file}\")\n",
    "\n",
    "if multimodal_file.exists():\n",
    "    with open(multimodal_file, 'r') as f:\n",
    "        multimodal_results = json.load(f)\n",
    "    print(f\"✓ Loaded multimodal results from {multimodal_file}\")\n",
    "else:\n",
    "    print(f\"✗ Multimodal results not found: {multimodal_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fd150ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 행동 분포 비교\n",
    "ACTION_NAMES = ['Fold', 'Check/Call', 'Raise Small', 'Raise Medium', 'Raise Large', 'All-in']\n",
    "\n",
    "if baseline_results and multimodal_results:\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "    \n",
    "    # Baseline\n",
    "    ax1 = axes[0]\n",
    "    x = np.arange(len(ACTION_NAMES))\n",
    "    width = 0.35\n",
    "    \n",
    "    baseline_dist = np.array(baseline_results['agent_action_distribution']) * 100\n",
    "    opponent_dist = np.array(baseline_results['opponent_action_distribution']) * 100\n",
    "    \n",
    "    ax1.bar(x - width/2, baseline_dist, width, label='Baseline Model', alpha=0.8)\n",
    "    ax1.bar(x + width/2, opponent_dist, width, label='Rule-based Agent', alpha=0.8)\n",
    "    \n",
    "    ax1.set_xlabel('Action')\n",
    "    ax1.set_ylabel('Frequency (%)')\n",
    "    ax1.set_title('Baseline Model: Action Distribution')\n",
    "    ax1.set_xticks(x)\n",
    "    ax1.set_xticklabels(ACTION_NAMES, rotation=45, ha='right')\n",
    "    ax1.legend()\n",
    "    ax1.grid(axis='y', alpha=0.3)\n",
    "    \n",
    "    # Multimodal\n",
    "    ax2 = axes[1]\n",
    "    \n",
    "    multimodal_dist = np.array(multimodal_results['agent_action_distribution']) * 100\n",
    "    opponent_dist2 = np.array(multimodal_results['opponent_action_distribution']) * 100\n",
    "    \n",
    "    ax2.bar(x - width/2, multimodal_dist, width, label='Multimodal Model', alpha=0.8)\n",
    "    ax2.bar(x + width/2, opponent_dist2, width, label='Rule-based Agent', alpha=0.8)\n",
    "    \n",
    "    ax2.set_xlabel('Action')\n",
    "    ax2.set_ylabel('Frequency (%)')\n",
    "    ax2.set_title('Multimodal Model: Action Distribution')\n",
    "    ax2.set_xticks(x)\n",
    "    ax2.set_xticklabels(ACTION_NAMES, rotation=45, ha='right')\n",
    "    ax2.legend()\n",
    "    ax2.grid(axis='y', alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(output_dir / 'action_distribution_comparison.png', dpi=150, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"\\n✓ Plot saved to {output_dir / 'action_distribution_comparison.png'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb553ccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agreement rate 비교\n",
    "if baseline_results and multimodal_results:\n",
    "    fig, ax = plt.subplots(figsize=(8, 6))\n",
    "    \n",
    "    models = ['Baseline', 'Multimodal']\n",
    "    agreement_rates = [\n",
    "        baseline_results['agreement_rate'],\n",
    "        multimodal_results['agreement_rate']\n",
    "    ]\n",
    "    \n",
    "    colors = ['#3498db', '#e74c3c']\n",
    "    bars = ax.bar(models, agreement_rates, color=colors, alpha=0.7, edgecolor='black')\n",
    "    \n",
    "    # Add value labels on bars\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        ax.text(bar.get_x() + bar.get_width()/2., height,\n",
    "                f'{height:.2f}%',\n",
    "                ha='center', va='bottom', fontsize=12, fontweight='bold')\n",
    "    \n",
    "    ax.set_ylabel('Agreement Rate (%)', fontsize=12)\n",
    "    ax.set_title('Agreement Rate with Rule-Based Agent', fontsize=14, fontweight='bold')\n",
    "    ax.set_ylim(0, max(agreement_rates) * 1.2)\n",
    "    ax.grid(axis='y', alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(output_dir / 'agreement_rate_comparison.png', dpi=150, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"\\n✓ Plot saved to {output_dir / 'agreement_rate_comparison.png'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15716f9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary table\n",
    "if baseline_results and multimodal_results:\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"COMPARISON SUMMARY\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    print(f\"\\n{'Metric':<30s} {'Baseline':<15s} {'Multimodal':<15s}\")\n",
    "    print(\"-\" * 60)\n",
    "    \n",
    "    print(f\"{'Agreement Rate':<30s} {baseline_results['agreement_rate']:>14.2f}% {multimodal_results['agreement_rate']:>14.2f}%\")\n",
    "    print(f\"{'Games Played':<30s} {baseline_results['n_games']:>14d} {multimodal_results['n_games']:>14d}\")\n",
    "    \n",
    "    print(\"\\n\" + \"-\" * 60)\n",
    "    print(\"Action Distribution:\")\n",
    "    print(\"-\" * 60)\n",
    "    \n",
    "    baseline_dist = np.array(baseline_results['agent_action_distribution']) * 100\n",
    "    multimodal_dist = np.array(multimodal_results['agent_action_distribution']) * 100\n",
    "    \n",
    "    for i, action in enumerate(ACTION_NAMES):\n",
    "        print(f\"{action:<30s} {baseline_dist[i]:>14.2f}% {multimodal_dist[i]:>14.2f}%\")\n",
    "    \n",
    "    # Sample dialogues from multimodal\n",
    "    if 'sample_dialogues' in multimodal_results:\n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"SAMPLE DIALOGUES (Multimodal Model)\")\n",
    "        print(\"=\"*60)\n",
    "        for i, dialogue in enumerate(multimodal_results['sample_dialogues'][:5], 1):\n",
    "            print(f\"{i}. \\\"{dialogue}\\\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "961a3ecd",
   "metadata": {},
   "source": [
    "## 7. 추가 분석 (선택사항)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0907eb8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix 스타일 시각화 (모델 vs Rule-based)\n",
    "if baseline_results:\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    \n",
    "    agent_actions = baseline_results['agent_actions']\n",
    "    opponent_actions = baseline_results['opponent_actions']\n",
    "    \n",
    "    cm = confusion_matrix(opponent_actions, agent_actions, labels=list(range(6)))\n",
    "    \n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "                xticklabels=ACTION_NAMES, yticklabels=ACTION_NAMES)\n",
    "    plt.ylabel('Rule-based Agent Action')\n",
    "    plt.xlabel('Baseline Model Action')\n",
    "    plt.title('Action Agreement Matrix: Baseline vs Rule-based')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(output_dir / 'baseline_confusion_matrix.png', dpi=150, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"\\n✓ Confusion matrix saved to {output_dir / 'baseline_confusion_matrix.png'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1352a59b",
   "metadata": {},
   "source": [
    "## 완료!\n",
    "\n",
    "평가가 완료되었습니다. 결과 파일들은 `outputs/` 디렉토리에 저장되었습니다:\n",
    "- `baseline_vs_rule_based.json` - Baseline 모델 평가 결과\n",
    "- `multimodal_vs_rule_based.json` - Multimodal 모델 평가 결과\n",
    "- `*.png` - 시각화 그래프들"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
