{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bfc53fa3",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "id": "0ba5f4eb",
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "source": [
    "import subprocess\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "print(f\"Python version: {sys.version}\")\n",
    "print(f\"Working directory: {Path.cwd()}\")\n",
    "\n",
    "# Check if required directories exist\n",
    "for dir_name in ['data', 'checkpoints', 'outputs', 'src']:\n",
    "    dir_path = Path(dir_name)\n",
    "    if dir_path.exists():\n",
    "        print(f\"âœ“ {dir_name}/ exists\")\n",
    "    else:\n",
    "        print(f\"âœ— {dir_name}/ not found\")\n",
    "        dir_path.mkdir(parents=True, exist_ok=True)\n",
    "        print(f\"  Created {dir_name}/\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59d98147",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì˜ì¡´ì„± ì„¤ì¹˜ (í•„ìš”ì‹œ ì‹¤í–‰)\n",
    "INSTALL_DEPENDENCIES = False  # Trueë¡œ ë³€ê²½í•˜ë©´ requirements.txt ì„¤ì¹˜\n",
    "\n",
    "if INSTALL_DEPENDENCIES:\n",
    "    print(\"Installing dependencies from requirements.txt...\")\n",
    "    result = subprocess.run([sys.executable, '-m', 'pip', 'install', '-r', 'requirements.txt'], \n",
    "                          capture_output=True, text=True)\n",
    "    \n",
    "    if result.returncode == 0:\n",
    "        print(\"âœ“ Dependencies installed successfully\")\n",
    "    else:\n",
    "        print(\"âœ— Installation failed\")\n",
    "        print(result.stderr)\n",
    "else:\n",
    "    print(\"âŠ˜ Dependency installation skipped\")\n",
    "    print(\"  (Set INSTALL_DEPENDENCIES = True to install)\")\n",
    "    \n",
    "# Check key packages\n",
    "print(\"\\nChecking key packages...\")\n",
    "required_packages = ['torch', 'transformers', 'sklearn', 'tqdm', 'numpy', 'matplotlib']\n",
    "missing_packages = []\n",
    "\n",
    "for package in required_packages:\n",
    "    try:\n",
    "        __import__(package)\n",
    "        print(f\"  âœ“ {package}\")\n",
    "    except ImportError:\n",
    "        print(f\"  âœ— {package} (missing)\")\n",
    "        missing_packages.append(package)\n",
    "\n",
    "if missing_packages:\n",
    "    print(f\"\\nâš  Missing packages: {', '.join(missing_packages)}\")\n",
    "    print(\"  Set INSTALL_DEPENDENCIES = True and re-run this cell\")\n",
    "else:\n",
    "    print(\"\\nâœ“ All required packages are available\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "139f2526",
   "metadata": {},
   "source": [
    "## ì˜ì¡´ì„± ì„¤ì¹˜ (ì„ íƒì‚¬í•­)\n",
    "\n",
    "ì²« ì‹¤í–‰ ì‹œ í•„ìš”í•œ íŒ¨í‚¤ì§€ë¥¼ ì„¤ì¹˜í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c38265e",
   "metadata": {},
   "source": [
    "## ì „ì²´ ì‹¤í–‰ ì„¤ì •"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b8dbf10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì‹¤í–‰í•  ë‹¨ê³„ ì„ íƒ (True/False)\n",
    "RUN_CONFIG = {\n",
    "    'preprocess': True,           # 1. ë°ì´í„° ì „ì²˜ë¦¬\n",
    "    'train_baseline': True,       # 2. Baseline ëª¨ë¸ í•™ìŠµ (ì§€ë„í•™ìŠµ)\n",
    "    'generate_text': True,        # 3. ëŒ€í™” ìƒì„±\n",
    "    'train_multimodal': True,     # 4. Multimodal ëª¨ë¸ í•™ìŠµ (ì§€ë„í•™ìŠµ)\n",
    "    'train_rl_baseline': True,    # 5. RL Baseline ëª¨ë¸ í•™ìŠµ (ê²Œì„ ìƒíƒœë§Œ)\n",
    "    'train_rl_multimodal': True,  # 6. RL Multimodal ëª¨ë¸ í•™ìŠµ (ê²Œì„ ìƒíƒœ + ëŒ€í™”)\n",
    "    'evaluate': True,             # 7. ì „ì²´ ëª¨ë¸ í‰ê°€\n",
    "    \n",
    "    # í‰ê°€ ì„¤ì •\n",
    "    'n_eval_games': 1000,    # í‰ê°€í•  ê²Œì„ ìˆ˜\n",
    "}\n",
    "\n",
    "print(\"ì‹¤í–‰ ì„¤ì •:\")\n",
    "for key, value in RUN_CONFIG.items():\n",
    "    print(f\"  {key:20s}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aed9a8a6",
   "metadata": {},
   "source": [
    "## Step 1: ë°ì´í„° ì „ì²˜ë¦¬\n",
    "\n",
    "Pluribus ë°ì´í„°ì…‹ì„ ë‹¤ìš´ë¡œë“œí•˜ê³  377ì°¨ì› featureë¡œ ë³€í™˜í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d98edfa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "if RUN_CONFIG['preprocess']:\n",
    "    print(\"=\"*60)\n",
    "    print(\"STEP 1: DATA PREPROCESSING\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    result = subprocess.run(['python', '1_preprocess_data.py'], capture_output=False)\n",
    "    \n",
    "    if result.returncode == 0:\n",
    "        print(\"\\nâœ“ Step 1 completed successfully\")\n",
    "    else:\n",
    "        print(\"\\nâœ— Step 1 failed\")\n",
    "        print(\"Stopping pipeline...\")\n",
    "        raise RuntimeError(\"Preprocessing failed\")\n",
    "else:\n",
    "    print(\"âŠ˜ Step 1 skipped\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d45ff85",
   "metadata": {},
   "source": [
    "## Step 2: Baseline ëª¨ë¸ í•™ìŠµ\n",
    "\n",
    "ê²Œì„ ìƒíƒœë§Œ ì‚¬ìš©í•˜ëŠ” MLP ëª¨ë¸ì„ í•™ìŠµí•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37874870",
   "metadata": {},
   "outputs": [],
   "source": [
    "if RUN_CONFIG['train_baseline']:\n",
    "    print(\"=\"*60)\n",
    "    print(\"STEP 2: TRAIN BASELINE MODEL\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    result = subprocess.run(['python', '2_train_baseline.py'], capture_output=False)\n",
    "    \n",
    "    if result.returncode == 0:\n",
    "        print(\"\\nâœ“ Step 2 completed successfully\")\n",
    "    else:\n",
    "        print(\"\\nâœ— Step 2 failed\")\n",
    "        print(\"Stopping pipeline...\")\n",
    "        raise RuntimeError(\"Baseline training failed\")\n",
    "else:\n",
    "    print(\"âŠ˜ Step 2 skipped\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e209f43",
   "metadata": {},
   "source": [
    "## Step 3: ëŒ€í™” ìƒì„±\n",
    "\n",
    "LLMì„ ì‚¬ìš©í•˜ì—¬ ê° ê²Œì„ ìƒíƒœì— ëŒ€í•œ ëŒ€í™”ë¥¼ ìƒì„±í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6b94a47",
   "metadata": {},
   "outputs": [],
   "source": [
    "if RUN_CONFIG['generate_text']:\n",
    "    print(\"=\"*60)\n",
    "    print(\"STEP 3: GENERATE DIALOGUES\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    result = subprocess.run(['python', '3_generate_dialogues.py'], capture_output=False)\n",
    "    \n",
    "    if result.returncode == 0:\n",
    "        print(\"\\nâœ“ Step 3 completed successfully\")\n",
    "    else:\n",
    "        print(\"\\nâœ— Step 3 failed\")\n",
    "        print(\"Stopping pipeline...\")\n",
    "        raise RuntimeError(\"Dialogue generation failed\")\n",
    "else:\n",
    "    print(\"âŠ˜ Step 3 skipped\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a3b82fb",
   "metadata": {},
   "source": [
    "## Step 4: Multimodal ëª¨ë¸ í•™ìŠµ\n",
    "\n",
    "ê²Œì„ ìƒíƒœì™€ ëŒ€í™”ë¥¼ ê²°í•©í•œ multimodal ëª¨ë¸ì„ í•™ìŠµí•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c04fed53",
   "metadata": {},
   "outputs": [],
   "source": [
    "if RUN_CONFIG['train_multimodal']:\n",
    "    print(\"=\"*60)\n",
    "    print(\"STEP 4: TRAIN MULTIMODAL MODEL\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    result = subprocess.run(['python', '4_train_multimodal.py'], capture_output=False)\n",
    "    \n",
    "    if result.returncode == 0:\n",
    "        print(\"\\nâœ“ Step 4 completed successfully\")\n",
    "    else:\n",
    "        print(\"\\nâœ— Step 4 failed\")\n",
    "        print(\"Stopping pipeline...\")\n",
    "        raise RuntimeError(\"Multimodal training failed\")\n",
    "else:\n",
    "    print(\"âŠ˜ Step 4 skipped\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b49e7a0",
   "metadata": {},
   "source": [
    "## Step 5: RL Baseline ëª¨ë¸ í•™ìŠµ (PPO)\n",
    "\n",
    "PPOë¥¼ ì‚¬ìš©í•˜ì—¬ ê²Œì„ ìƒíƒœë§Œìœ¼ë¡œ í•™ìŠµí•˜ëŠ” ê°•í™”í•™ìŠµ ëª¨ë¸ì„ í•™ìŠµí•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d00a0ba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "if RUN_CONFIG['train_rl_baseline']:\n",
    "    print(\"=\"*60)\n",
    "    print(\"STEP 5: TRAIN RL BASELINE MODEL (PPO)\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    result = subprocess.run(['python', '5_train_rl_baseline.py'], capture_output=False)\n",
    "    \n",
    "    if result.returncode == 0:\n",
    "        print(\"\\nâœ“ Step 5 completed successfully\")\n",
    "    else:\n",
    "        print(\"\\nâœ— Step 5 failed\")\n",
    "        print(\"âš  Continuing pipeline (RL training is optional)...\")\n",
    "else:\n",
    "    print(\"âŠ˜ Step 5 skipped\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2348f13",
   "metadata": {},
   "source": [
    "## Step 6: RL Multimodal ëª¨ë¸ í•™ìŠµ (PPO)\n",
    "\n",
    "PPOë¥¼ ì‚¬ìš©í•˜ì—¬ ê²Œì„ ìƒíƒœì™€ ëŒ€í™”ë¥¼ ê²°í•©í•œ ê°•í™”í•™ìŠµ ëª¨ë¸ì„ í•™ìŠµí•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2859d50b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if RUN_CONFIG['train_rl_multimodal']:\n",
    "    print(\"=\"*60)\n",
    "    print(\"STEP 6: TRAIN RL MULTIMODAL MODEL (PPO)\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    result = subprocess.run(['python', '6_train_rl_multimodal.py'], capture_output=False)\n",
    "    \n",
    "    if result.returncode == 0:\n",
    "        print(\"\\nâœ“ Step 6 completed successfully\")\n",
    "    else:\n",
    "        print(\"\\nâœ— Step 6 failed\")\n",
    "        print(\"âš  Continuing pipeline (RL training is optional)...\")\n",
    "else:\n",
    "    print(\"âŠ˜ Step 6 skipped\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "548c0073",
   "metadata": {},
   "source": [
    "## Step 7: ì „ì²´ ëª¨ë¸ í‰ê°€\n",
    "\n",
    "í•™ìŠµëœ ëª¨ë“  ëª¨ë¸(ì§€ë„í•™ìŠµ + ê°•í™”í•™ìŠµ)ì„ rule-based agentì™€ ëŒ€ê²°ì‹œì¼œ í‰ê°€í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33f3db2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if RUN_CONFIG['evaluate']:\n",
    "    print(\"=\"*60)\n",
    "    print(\"STEP 7: EVALUATE ALL MODELS\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    n_games = RUN_CONFIG['n_eval_games']\n",
    "    results = {}\n",
    "    \n",
    "    # Evaluate Supervised Baseline\n",
    "    print(\"\\n--- Evaluating Supervised Baseline Model ---\")\n",
    "    result = subprocess.run([\n",
    "        'python', '7_evaluate_vs_rule_based.py',\n",
    "        '--model_type', 'baseline',\n",
    "        '--model_path', 'checkpoints/baseline_best.pt',\n",
    "        '--n_games', str(n_games),\n",
    "        '--output_dir', 'outputs'\n",
    "    ], capture_output=False)\n",
    "    results['baseline'] = (result.returncode == 0)\n",
    "    \n",
    "    # Evaluate Supervised Multimodal\n",
    "    print(\"\\n--- Evaluating Supervised Multimodal Model ---\")\n",
    "    result = subprocess.run([\n",
    "        'python', '7_evaluate_vs_rule_based.py',\n",
    "        '--model_type', 'multimodal',\n",
    "        '--model_path', 'checkpoints/multimodal_best.pt',\n",
    "        '--n_games', str(n_games),\n",
    "        '--output_dir', 'outputs'\n",
    "    ], capture_output=False)\n",
    "    results['multimodal'] = (result.returncode == 0)\n",
    "    \n",
    "    # Evaluate RL Baseline\n",
    "    print(\"\\n--- Evaluating RL Baseline Model ---\")\n",
    "    result = subprocess.run([\n",
    "        'python', '7_evaluate_vs_rule_based.py',\n",
    "        '--model_type', 'rl_baseline',\n",
    "        '--model_path', 'checkpoints/rl_baseline_best.pt',\n",
    "        '--n_games', str(n_games),\n",
    "        '--output_dir', 'outputs'\n",
    "    ], capture_output=False)\n",
    "    results['rl_baseline'] = (result.returncode == 0)\n",
    "    \n",
    "    # Evaluate RL Multimodal\n",
    "    print(\"\\n--- Evaluating RL Multimodal Model ---\")\n",
    "    result = subprocess.run([\n",
    "        'python', '7_evaluate_vs_rule_based.py',\n",
    "        '--model_type', 'rl_multimodal',\n",
    "        '--model_path', 'checkpoints/rl_multimodal_best.pt',\n",
    "        '--n_games', str(n_games),\n",
    "        '--output_dir', 'outputs'\n",
    "    ], capture_output=False)\n",
    "    results['rl_multimodal'] = (result.returncode == 0)\n",
    "    \n",
    "    # Summary\n",
    "    success_count = sum(results.values())\n",
    "    if success_count == len(results):\n",
    "        print(\"\\nâœ“ Step 7 completed successfully (all models evaluated)\")\n",
    "    elif success_count > 0:\n",
    "        print(f\"\\nâš  Step 7 completed with some errors ({success_count}/{len(results)} models evaluated)\")\n",
    "    else:\n",
    "        print(\"\\nâœ— Step 7 failed (no models evaluated)\")\n",
    "else:\n",
    "    print(\"âŠ˜ Step 7 skipped\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15d93604",
   "metadata": {},
   "source": [
    "## ê²°ê³¼ í™•ì¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20ac3187",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"EVALUATION RESULTS SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Define model names and their file paths\n",
    "models = {\n",
    "    'Supervised Baseline': 'baseline_vs_rule_based.json',\n",
    "    'Supervised Multimodal': 'multimodal_vs_rule_based.json',\n",
    "    'RL Baseline': 'rl_baseline_vs_rule_based.json',\n",
    "    'RL Multimodal': 'rl_multimodal_vs_rule_based.json'\n",
    "}\n",
    "\n",
    "output_dir = Path('outputs')\n",
    "results = {}\n",
    "available_models = []\n",
    "\n",
    "# Load all available results\n",
    "for model_name, filename in models.items():\n",
    "    filepath = output_dir / filename\n",
    "    if filepath.exists():\n",
    "        with open(filepath, 'r') as f:\n",
    "            results[model_name] = json.load(f)\n",
    "            available_models.append(model_name)\n",
    "\n",
    "if len(available_models) == 0:\n",
    "    print(\"\\nâš  No evaluation results found\")\n",
    "    print(\"  Make sure to run evaluation steps (Step 5 and/or Step 8) first.\")\n",
    "else:\n",
    "    # Display comparison table\n",
    "    print(f\"\\n{'Model':<25s} {'Total Profit':>15s} {'Avg/Hand':>12s} {'Win Rate':>12s}\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    for model_name in available_models:\n",
    "        result = results[model_name]\n",
    "        total_profit = result['total_profit']\n",
    "        avg_profit = result['avg_profit_per_hand']\n",
    "        win_rate = result['win_rate']\n",
    "        \n",
    "        print(f\"{model_name:<25s} {total_profit:>15.1f} {avg_profit:>12.2f} {win_rate:>11.1f}%\")\n",
    "    \n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    # Find best model by total profit\n",
    "    best_model = max(available_models, key=lambda m: results[m]['total_profit'])\n",
    "    best_profit = results[best_model]['total_profit']\n",
    "    print(f\"\\nğŸ† Best Model: {best_model} (Profit: {best_profit:+.1f} BB)\")\n",
    "    \n",
    "    # Visualization\n",
    "    if len(available_models) >= 2:\n",
    "        fig, axes = plt.subplots(1, 3, figsize=(16, 5))\n",
    "        \n",
    "        # Plot 1: Total Profit\n",
    "        ax = axes[0]\n",
    "        profits = [results[m]['total_profit'] for m in available_models]\n",
    "        colors = ['#3498db', '#e74c3c', '#2ecc71', '#f39c12'][:len(available_models)]\n",
    "        bars = ax.bar(range(len(available_models)), profits, color=colors, alpha=0.7, \n",
    "                     edgecolor='black', linewidth=2)\n",
    "        ax.axhline(0, color='gray', linestyle='--', linewidth=1)\n",
    "        ax.set_ylabel('Total Profit (BB)', fontsize=12, fontweight='bold')\n",
    "        ax.set_title('Total Profit Comparison', fontsize=13, fontweight='bold')\n",
    "        ax.set_xticks(range(len(available_models)))\n",
    "        ax.set_xticklabels(available_models, rotation=15, ha='right')\n",
    "        ax.grid(axis='y', alpha=0.3)\n",
    "        \n",
    "        for i, bar in enumerate(bars):\n",
    "            height = bar.get_height()\n",
    "            ax.text(bar.get_x() + bar.get_width()/2., height,\n",
    "                    f'{height:.1f}',\n",
    "                    ha='center', va='bottom' if height > 0 else 'top',\n",
    "                    fontweight='bold', fontsize=10)\n",
    "        \n",
    "        # Plot 2: Win Rate\n",
    "        ax = axes[1]\n",
    "        win_rates = [results[m]['win_rate'] for m in available_models]\n",
    "        bars = ax.bar(range(len(available_models)), win_rates, color=colors, alpha=0.7,\n",
    "                     edgecolor='black', linewidth=2)\n",
    "        ax.set_ylabel('Win Rate (%)', fontsize=12, fontweight='bold')\n",
    "        ax.set_title('Win Rate Comparison', fontsize=13, fontweight='bold')\n",
    "        ax.set_xticks(range(len(available_models)))\n",
    "        ax.set_xticklabels(available_models, rotation=15, ha='right')\n",
    "        ax.set_ylim([0, 100])\n",
    "        ax.grid(axis='y', alpha=0.3)\n",
    "        \n",
    "        for i, bar in enumerate(bars):\n",
    "            height = bar.get_height()\n",
    "            ax.text(bar.get_x() + bar.get_width()/2., height,\n",
    "                    f'{height:.1f}%',\n",
    "                    ha='center', va='bottom',\n",
    "                    fontweight='bold', fontsize=10)\n",
    "        \n",
    "        # Plot 3: Avg Profit per Hand\n",
    "        ax = axes[2]\n",
    "        avg_profits = [results[m]['avg_profit_per_hand'] for m in available_models]\n",
    "        bars = ax.bar(range(len(available_models)), avg_profits, color=colors, alpha=0.7,\n",
    "                     edgecolor='black', linewidth=2)\n",
    "        ax.axhline(0, color='gray', linestyle='--', linewidth=1)\n",
    "        ax.set_ylabel('Avg Profit per Hand (BB)', fontsize=12, fontweight='bold')\n",
    "        ax.set_title('Efficiency Comparison', fontsize=13, fontweight='bold')\n",
    "        ax.set_xticks(range(len(available_models)))\n",
    "        ax.set_xticklabels(available_models, rotation=15, ha='right')\n",
    "        ax.grid(axis='y', alpha=0.3)\n",
    "        \n",
    "        for i, bar in enumerate(bars):\n",
    "            height = bar.get_height()\n",
    "            ax.text(bar.get_x() + bar.get_width()/2., height,\n",
    "                    f'{height:.3f}',\n",
    "                    ha='center', va='bottom' if height > 0 else 'top',\n",
    "                    fontweight='bold', fontsize=10)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig('outputs/all_models_comparison.png', dpi=150, bbox_inches='tight')\n",
    "        print(\"\\nğŸ“Š Visualization saved: outputs/all_models_comparison.png\")\n",
    "        plt.show()\n",
    "    \n",
    "    # Detailed comparison\n",
    "    if len(available_models) >= 2:\n",
    "        print(\"\\n\" + \"=\"*70)\n",
    "        print(\"DETAILED COMPARISON\")\n",
    "        print(\"=\"*70)\n",
    "        \n",
    "        # Compare supervised vs RL (if both available)\n",
    "        if 'Supervised Baseline' in results and 'RL Baseline' in results:\n",
    "            print(\"\\n--- Baseline: Supervised vs RL ---\")\n",
    "            sup_profit = results['Supervised Baseline']['total_profit']\n",
    "            rl_profit = results['RL Baseline']['total_profit']\n",
    "            diff = rl_profit - sup_profit\n",
    "            print(f\"  Supervised: {sup_profit:+.1f} BB\")\n",
    "            print(f\"  RL (PPO):   {rl_profit:+.1f} BB\")\n",
    "            print(f\"  Difference: {diff:+.1f} BB ({diff/abs(sup_profit)*100 if sup_profit != 0 else 0:+.1f}%)\")\n",
    "        \n",
    "        if 'Supervised Multimodal' in results and 'RL Multimodal' in results:\n",
    "            print(\"\\n--- Multimodal: Supervised vs RL ---\")\n",
    "            sup_profit = results['Supervised Multimodal']['total_profit']\n",
    "            rl_profit = results['RL Multimodal']['total_profit']\n",
    "            diff = rl_profit - sup_profit\n",
    "            print(f\"  Supervised: {sup_profit:+.1f} BB\")\n",
    "            print(f\"  RL (PPO):   {rl_profit:+.1f} BB\")\n",
    "            print(f\"  Difference: {diff:+.1f} BB ({diff/abs(sup_profit)*100 if sup_profit != 0 else 0:+.1f}%)\")\n",
    "        \n",
    "        # Compare baseline vs multimodal effect\n",
    "        if 'RL Baseline' in results and 'RL Multimodal' in results:\n",
    "            print(\"\\n--- RL Models: Baseline vs Multimodal ---\")\n",
    "            baseline_profit = results['RL Baseline']['total_profit']\n",
    "            multimodal_profit = results['RL Multimodal']['total_profit']\n",
    "            diff = multimodal_profit - baseline_profit\n",
    "            print(f\"  Baseline:   {baseline_profit:+.1f} BB\")\n",
    "            print(f\"  Multimodal: {multimodal_profit:+.1f} BB\")\n",
    "            print(f\"  Dialogue Impact: {diff:+.1f} BB ({diff/abs(baseline_profit)*100 if baseline_profit != 0 else 0:+.1f}%)\")\n",
    "        \n",
    "        print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91df21a5",
   "metadata": {},
   "source": [
    "## ì™„ë£Œ!\n",
    "\n",
    "ì „ì²´ íŒŒì´í”„ë¼ì¸ì´ ì‹¤í–‰ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "### ìƒì„±ëœ íŒŒì¼ë“¤\n",
    "- `data/processed/` - ì „ì²˜ë¦¬ëœ ë°ì´í„°\n",
    "- `data/text/` - ìƒì„±ëœ ëŒ€í™”\n",
    "- `checkpoints/` - í•™ìŠµëœ ëª¨ë¸ (ì§€ë„í•™ìŠµ + ê°•í™”í•™ìŠµ)\n",
    "- `outputs/` - í‰ê°€ ê²°ê³¼ ë° ì‹œê°í™”\n",
    "\n",
    "### í•™ìŠµëœ ëª¨ë¸ë“¤\n",
    "1. **Supervised Learning (ì§€ë„í•™ìŠµ)**\n",
    "   - Baseline: ê²Œì„ ìƒíƒœë§Œ ì‚¬ìš© (MLP)\n",
    "   - Multimodal: ê²Œì„ ìƒíƒœ + ëŒ€í™” ì‚¬ìš©\n",
    "\n",
    "2. **Reinforcement Learning (PPO)**\n",
    "   - RL Baseline: ê²Œì„ ìƒíƒœë§Œ ì‚¬ìš© (Actor-Critic)\n",
    "   - RL Multimodal: ê²Œì„ ìƒíƒœ + ëŒ€í™” ì‚¬ìš© (Actor-Critic)\n",
    "\n",
    "### ë‹¤ìŒ ë‹¨ê³„\n",
    "- 4ê°€ì§€ ëª¨ë¸ ë¹„êµ ë¶„ì„\n",
    "- ê°œë³„ ìŠ¤í¬ë¦½íŠ¸ë¥¼ ì§ì ‘ ì‹¤í–‰í•˜ì—¬ í•˜ì´í¼íŒŒë¼ë¯¸í„° ì¡°ì •\n",
    "- RL ëª¨ë¸ì˜ í•™ìŠµ ê³¡ì„  ë¶„ì„ (outputs/rl_*_training.png)"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## [optional] í›ˆë ¨ëœ ë´‡ ìƒëŒ€ í”Œë ˆì´",
   "id": "7df4964fe1f565c5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "subprocess.run(['python', '8_evaluate_vs_rule_based.py'])",
   "id": "f1484a1a56e02a3a"
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
