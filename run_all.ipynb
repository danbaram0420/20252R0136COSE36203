{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bfc53fa3",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ba5f4eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "print(f\"Python version: {sys.version}\")\n",
    "print(f\"Working directory: {Path.cwd()}\")\n",
    "\n",
    "# Check if required directories exist\n",
    "for dir_name in ['data', 'checkpoints', 'outputs', 'src']:\n",
    "    dir_path = Path(dir_name)\n",
    "    if dir_path.exists():\n",
    "        print(f\"âœ“ {dir_name}/ exists\")\n",
    "    else:\n",
    "        print(f\"âœ— {dir_name}/ not found\")\n",
    "        dir_path.mkdir(parents=True, exist_ok=True)\n",
    "        print(f\"  Created {dir_name}/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59d98147",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì˜ì¡´ì„± ì„¤ì¹˜ (í•„ìš”ì‹œ ì‹¤í–‰)\n",
    "INSTALL_DEPENDENCIES = False  # Trueë¡œ ë³€ê²½í•˜ë©´ requirements.txt ì„¤ì¹˜\n",
    "\n",
    "if INSTALL_DEPENDENCIES:\n",
    "    print(\"Installing dependencies from requirements.txt...\")\n",
    "    result = subprocess.run([sys.executable, '-m', 'pip', 'install', '-r', 'requirements.txt'], \n",
    "                          capture_output=True, text=True)\n",
    "    \n",
    "    if result.returncode == 0:\n",
    "        print(\"âœ“ Dependencies installed successfully\")\n",
    "    else:\n",
    "        print(\"âœ— Installation failed\")\n",
    "        print(result.stderr)\n",
    "else:\n",
    "    print(\"âŠ˜ Dependency installation skipped\")\n",
    "    print(\"  (Set INSTALL_DEPENDENCIES = True to install)\")\n",
    "    \n",
    "# Check key packages\n",
    "print(\"\\nChecking key packages...\")\n",
    "required_packages = ['torch', 'transformers', 'sklearn', 'tqdm', 'numpy', 'matplotlib']\n",
    "missing_packages = []\n",
    "\n",
    "for package in required_packages:\n",
    "    try:\n",
    "        __import__(package)\n",
    "        print(f\"  âœ“ {package}\")\n",
    "    except ImportError:\n",
    "        print(f\"  âœ— {package} (missing)\")\n",
    "        missing_packages.append(package)\n",
    "\n",
    "if missing_packages:\n",
    "    print(f\"\\nâš  Missing packages: {', '.join(missing_packages)}\")\n",
    "    print(\"  Set INSTALL_DEPENDENCIES = True and re-run this cell\")\n",
    "else:\n",
    "    print(\"\\nâœ“ All required packages are available\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "139f2526",
   "metadata": {},
   "source": [
    "## ì˜ì¡´ì„± ì„¤ì¹˜ (ì„ íƒì‚¬í•­)\n",
    "\n",
    "ì²« ì‹¤í–‰ ì‹œ í•„ìš”í•œ íŒ¨í‚¤ì§€ë¥¼ ì„¤ì¹˜í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c38265e",
   "metadata": {},
   "source": [
    "## ì „ì²´ ì‹¤í–‰ ì„¤ì •"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b8dbf10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì‹¤í–‰í•  ë‹¨ê³„ ì„ íƒ (True/False)\n",
    "RUN_CONFIG = {\n",
    "    'preprocess': True,      # 1. ë°ì´í„° ì „ì²˜ë¦¬\n",
    "    'train_baseline': True,  # 2. Baseline ëª¨ë¸ í•™ìŠµ\n",
    "    'generate_text': True,   # 3. ëŒ€í™” ìƒì„±\n",
    "    'train_multimodal': True,# 4. Multimodal ëª¨ë¸ í•™ìŠµ\n",
    "    'evaluate': True,        # 5. í‰ê°€\n",
    "    \n",
    "    # í‰ê°€ ì„¤ì •\n",
    "    'n_eval_games': 1000,    # í‰ê°€í•  ê²Œì„ ìˆ˜\n",
    "}\n",
    "\n",
    "print(\"ì‹¤í–‰ ì„¤ì •:\")\n",
    "for key, value in RUN_CONFIG.items():\n",
    "    print(f\"  {key:20s}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aed9a8a6",
   "metadata": {},
   "source": [
    "## Step 1: ë°ì´í„° ì „ì²˜ë¦¬\n",
    "\n",
    "Pluribus ë°ì´í„°ì…‹ì„ ë‹¤ìš´ë¡œë“œí•˜ê³  377ì°¨ì› featureë¡œ ë³€í™˜í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d98edfa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "if RUN_CONFIG['preprocess']:\n",
    "    print(\"=\"*60)\n",
    "    print(\"STEP 1: DATA PREPROCESSING\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    result = subprocess.run(['python', '1_preprocess_data.py'], capture_output=False)\n",
    "    \n",
    "    if result.returncode == 0:\n",
    "        print(\"\\nâœ“ Step 1 completed successfully\")\n",
    "    else:\n",
    "        print(\"\\nâœ— Step 1 failed\")\n",
    "        print(\"Stopping pipeline...\")\n",
    "        raise RuntimeError(\"Preprocessing failed\")\n",
    "else:\n",
    "    print(\"âŠ˜ Step 1 skipped\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d45ff85",
   "metadata": {},
   "source": [
    "## Step 2: Baseline ëª¨ë¸ í•™ìŠµ\n",
    "\n",
    "ê²Œì„ ìƒíƒœë§Œ ì‚¬ìš©í•˜ëŠ” MLP ëª¨ë¸ì„ í•™ìŠµí•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37874870",
   "metadata": {},
   "outputs": [],
   "source": [
    "if RUN_CONFIG['train_baseline']:\n",
    "    print(\"=\"*60)\n",
    "    print(\"STEP 2: TRAIN BASELINE MODEL\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    result = subprocess.run(['python', '2_train_baseline.py'], capture_output=False)\n",
    "    \n",
    "    if result.returncode == 0:\n",
    "        print(\"\\nâœ“ Step 2 completed successfully\")\n",
    "    else:\n",
    "        print(\"\\nâœ— Step 2 failed\")\n",
    "        print(\"Stopping pipeline...\")\n",
    "        raise RuntimeError(\"Baseline training failed\")\n",
    "else:\n",
    "    print(\"âŠ˜ Step 2 skipped\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e209f43",
   "metadata": {},
   "source": [
    "## Step 3: ëŒ€í™” ìƒì„±\n",
    "\n",
    "LLMì„ ì‚¬ìš©í•˜ì—¬ ê° ê²Œì„ ìƒíƒœì— ëŒ€í•œ ëŒ€í™”ë¥¼ ìƒì„±í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6b94a47",
   "metadata": {},
   "outputs": [],
   "source": [
    "if RUN_CONFIG['generate_text']:\n",
    "    print(\"=\"*60)\n",
    "    print(\"STEP 3: GENERATE DIALOGUES\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    result = subprocess.run(['python', '3_generate_dialogues.py'], capture_output=False)\n",
    "    \n",
    "    if result.returncode == 0:\n",
    "        print(\"\\nâœ“ Step 3 completed successfully\")\n",
    "    else:\n",
    "        print(\"\\nâœ— Step 3 failed\")\n",
    "        print(\"Stopping pipeline...\")\n",
    "        raise RuntimeError(\"Dialogue generation failed\")\n",
    "else:\n",
    "    print(\"âŠ˜ Step 3 skipped\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a3b82fb",
   "metadata": {},
   "source": [
    "## Step 4: Multimodal ëª¨ë¸ í•™ìŠµ\n",
    "\n",
    "ê²Œì„ ìƒíƒœì™€ ëŒ€í™”ë¥¼ ê²°í•©í•œ multimodal ëª¨ë¸ì„ í•™ìŠµí•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c04fed53",
   "metadata": {},
   "outputs": [],
   "source": [
    "if RUN_CONFIG['train_multimodal']:\n",
    "    print(\"=\"*60)\n",
    "    print(\"STEP 4: TRAIN MULTIMODAL MODEL\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    result = subprocess.run(['python', '4_train_multimodal.py'], capture_output=False)\n",
    "    \n",
    "    if result.returncode == 0:\n",
    "        print(\"\\nâœ“ Step 4 completed successfully\")\n",
    "    else:\n",
    "        print(\"\\nâœ— Step 4 failed\")\n",
    "        print(\"Stopping pipeline...\")\n",
    "        raise RuntimeError(\"Multimodal training failed\")\n",
    "else:\n",
    "    print(\"âŠ˜ Step 4 skipped\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b49e7a0",
   "metadata": {},
   "source": [
    "## Step 5: Rule-based Agent í‰ê°€\n",
    "\n",
    "í•™ìŠµëœ ëª¨ë¸ì„ rule-based agentì™€ ëŒ€ê²°ì‹œì¼œ í‰ê°€í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d00a0ba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "if RUN_CONFIG['evaluate']:\n",
    "    print(\"=\"*60)\n",
    "    print(\"STEP 5: EVALUATION\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    n_games = RUN_CONFIG['n_eval_games']\n",
    "    \n",
    "    # Evaluate baseline\n",
    "    print(\"\\n--- Evaluating Baseline Model ---\")\n",
    "    result_baseline = subprocess.run([\n",
    "        'python', '5_evaluate_vs_rule_based.py',\n",
    "        '--model_type', 'baseline',\n",
    "        '--model_path', 'checkpoints/baseline_best.pt',\n",
    "        '--n_games', str(n_games),\n",
    "        '--output_dir', 'outputs'\n",
    "    ], capture_output=False)\n",
    "    \n",
    "    if result_baseline.returncode != 0:\n",
    "        print(\"\\nâœ— Baseline evaluation failed\")\n",
    "    \n",
    "    # Evaluate multimodal\n",
    "    print(\"\\n--- Evaluating Multimodal Model ---\")\n",
    "    result_multimodal = subprocess.run([\n",
    "        'python', '5_evaluate_vs_rule_based.py',\n",
    "        '--model_type', 'multimodal',\n",
    "        '--model_path', 'checkpoints/multimodal_best.pt',\n",
    "        '--n_games', str(n_games),\n",
    "        '--output_dir', 'outputs'\n",
    "    ], capture_output=False)\n",
    "    \n",
    "    if result_multimodal.returncode != 0:\n",
    "        print(\"\\nâœ— Multimodal evaluation failed\")\n",
    "    \n",
    "    if result_baseline.returncode == 0 and result_multimodal.returncode == 0:\n",
    "        print(\"\\nâœ“ Step 5 completed successfully\")\n",
    "    else:\n",
    "        print(\"\\nâš  Step 5 completed with errors\")\n",
    "else:\n",
    "    print(\"âŠ˜ Step 5 skipped\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15d93604",
   "metadata": {},
   "source": [
    "## ê²°ê³¼ í™•ì¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20ac3187",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"EVALUATION RESULTS: Baseline vs Multimodal\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Load evaluation results\n",
    "output_dir = Path('outputs')\n",
    "baseline_file = output_dir / 'baseline_vs_rule_based.json'\n",
    "multimodal_file = output_dir / 'multimodal_vs_rule_based.json'\n",
    "\n",
    "if baseline_file.exists() and multimodal_file.exists():\n",
    "    with open(baseline_file, 'r') as f:\n",
    "        baseline = json.load(f)\n",
    "    \n",
    "    with open(multimodal_file, 'r') as f:\n",
    "        multimodal = json.load(f)\n",
    "    \n",
    "    # Display comparison table\n",
    "    print(f\"\\n{'Metric':<25s} {'Baseline':>15s} {'Multimodal':>15s} {'Diff':>12s}\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    # Total profit\n",
    "    b_profit = baseline['total_profit']\n",
    "    m_profit = multimodal['total_profit']\n",
    "    diff = m_profit - b_profit\n",
    "    diff_str = f\"+{diff:.1f}\" if diff > 0 else f\"{diff:.1f}\"\n",
    "    print(f\"{'Total Profit':<25s} {b_profit:>15.1f} {m_profit:>15.1f} {diff_str:>12s}\")\n",
    "    \n",
    "    # Avg profit per hand\n",
    "    b_avg = baseline['avg_profit_per_hand']\n",
    "    m_avg = multimodal['avg_profit_per_hand']\n",
    "    diff = m_avg - b_avg\n",
    "    diff_str = f\"+{diff:.2f}\" if diff > 0 else f\"{diff:.2f}\"\n",
    "    print(f\"{'Avg Profit/Hand':<25s} {b_avg:>15.2f} {m_avg:>15.2f} {diff_str:>12s}\")\n",
    "    \n",
    "    # Win rate\n",
    "    b_wr = baseline['win_rate']\n",
    "    m_wr = multimodal['win_rate']\n",
    "    diff = m_wr - b_wr\n",
    "    diff_str = f\"+{diff:.1f}%\" if diff > 0 else f\"{diff:.1f}%\"\n",
    "    print(f\"{'Win Rate':<25s} {b_wr:>14.1f}% {m_wr:>14.1f}% {diff_str:>12s}\")\n",
    "    \n",
    "    print(\"-\" * 70)\n",
    "    \n",
    "    # Win/Loss breakdown\n",
    "    b_wins = baseline['wins']\n",
    "    m_wins = multimodal['wins']\n",
    "    b_losses = baseline['losses']\n",
    "    m_losses = multimodal['losses']\n",
    "    \n",
    "    print(f\"{'Wins':<25s} {b_wins:>15d} {m_wins:>15d} {m_wins - b_wins:>+12d}\")\n",
    "    print(f\"{'Losses':<25s} {b_losses:>15d} {m_losses:>15d} {m_losses - b_losses:>+12d}\")\n",
    "    print(f\"{'Games Played':<25s} {baseline['n_games']:>15d} {multimodal['n_games']:>15d}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 70)\n",
    "    \n",
    "    # Winner announcement\n",
    "    if m_profit > b_profit:\n",
    "        winner = \"ğŸ† Multimodal\"\n",
    "        improvement = ((m_profit - b_profit) / abs(b_profit) * 100) if b_profit != 0 else 0\n",
    "        print(f\"{winner} wins with {improvement:+.1f}% profit improvement!\")\n",
    "    elif m_profit < b_profit:\n",
    "        winner = \"ğŸ† Baseline\"\n",
    "        improvement = ((b_profit - m_profit) / abs(m_profit) * 100) if m_profit != 0 else 0\n",
    "        print(f\"{winner} wins with {improvement:+.1f}% profit advantage!\")\n",
    "    else:\n",
    "        print(\"ğŸ¤ It's a tie!\")\n",
    "    \n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    # Visualization\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "    \n",
    "    # Plot 1: Total Profit\n",
    "    ax = axes[0]\n",
    "    models = ['Baseline', 'Multimodal']\n",
    "    profits = [b_profit, m_profit]\n",
    "    colors = ['#3498db', '#e74c3c']\n",
    "    bars = ax.bar(models, profits, color=colors, alpha=0.7, edgecolor='black', linewidth=2)\n",
    "    ax.axhline(0, color='gray', linestyle='--', linewidth=1)\n",
    "    ax.set_ylabel('Total Profit', fontsize=12, fontweight='bold')\n",
    "    ax.set_title('Total Profit Comparison', fontsize=13, fontweight='bold')\n",
    "    ax.grid(axis='y', alpha=0.3)\n",
    "    \n",
    "    # Add value labels\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        ax.text(bar.get_x() + bar.get_width()/2., height,\n",
    "                f'{height:.1f}',\n",
    "                ha='center', va='bottom' if height > 0 else 'top',\n",
    "                fontweight='bold', fontsize=11)\n",
    "    \n",
    "    # Plot 2: Win Rate\n",
    "    ax = axes[1]\n",
    "    win_rates = [b_wr, m_wr]\n",
    "    bars = ax.bar(models, win_rates, color=colors, alpha=0.7, edgecolor='black', linewidth=2)\n",
    "    ax.set_ylabel('Win Rate (%)', fontsize=12, fontweight='bold')\n",
    "    ax.set_title('Win Rate Comparison', fontsize=13, fontweight='bold')\n",
    "    ax.set_ylim([0, 100])\n",
    "    ax.grid(axis='y', alpha=0.3)\n",
    "    \n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        ax.text(bar.get_x() + bar.get_width()/2., height,\n",
    "                f'{height:.1f}%',\n",
    "                ha='center', va='bottom',\n",
    "                fontweight='bold', fontsize=11)\n",
    "    \n",
    "    # Plot 3: Wins vs Losses\n",
    "    ax = axes[2]\n",
    "    x = np.arange(len(models))\n",
    "    width = 0.35\n",
    "    bars1 = ax.bar(x - width/2, [b_wins, m_wins], width, label='Wins', \n",
    "                   color='#2ecc71', alpha=0.7, edgecolor='black', linewidth=2)\n",
    "    bars2 = ax.bar(x + width/2, [b_losses, m_losses], width, label='Losses', \n",
    "                   color='#e67e22', alpha=0.7, edgecolor='black', linewidth=2)\n",
    "    ax.set_ylabel('Count', fontsize=12, fontweight='bold')\n",
    "    ax.set_title('Wins vs Losses', fontsize=13, fontweight='bold')\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels(models)\n",
    "    ax.legend(fontsize=10)\n",
    "    ax.grid(axis='y', alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('outputs/comparison_summary.png', dpi=150, bbox_inches='tight')\n",
    "    print(\"\\nğŸ“Š Visualization saved: outputs/comparison_summary.png\")\n",
    "    plt.show()\n",
    "    \n",
    "else:\n",
    "    print(\"\\nâš  Evaluation results not found\")\n",
    "    print(f\"  Expected files:\")\n",
    "    print(f\"    - {baseline_file}\")\n",
    "    print(f\"    - {multimodal_file}\")\n",
    "    print(f\"\\n  Make sure to run Step 5 (Evaluation) first.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91df21a5",
   "metadata": {},
   "source": [
    "## ì™„ë£Œ!\n",
    "\n",
    "ì „ì²´ íŒŒì´í”„ë¼ì¸ì´ ì‹¤í–‰ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "### ìƒì„±ëœ íŒŒì¼ë“¤\n",
    "- `data/processed/` - ì „ì²˜ë¦¬ëœ ë°ì´í„°\n",
    "- `data/text/` - ìƒì„±ëœ ëŒ€í™”\n",
    "- `checkpoints/` - í•™ìŠµëœ ëª¨ë¸\n",
    "- `outputs/` - í‰ê°€ ê²°ê³¼ ë° ì‹œê°í™”\n",
    "\n",
    "### ë‹¤ìŒ ë‹¨ê³„\n",
    "- [evaluate_models.ipynb](evaluate_models.ipynb)ì—ì„œ ìƒì„¸í•œ ê²°ê³¼ ë¶„ì„ ë° ì‹œê°í™”\n",
    "- ê°œë³„ ìŠ¤í¬ë¦½íŠ¸ë¥¼ ì§ì ‘ ì‹¤í–‰í•˜ì—¬ íŒŒë¼ë¯¸í„° ì¡°ì •"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
